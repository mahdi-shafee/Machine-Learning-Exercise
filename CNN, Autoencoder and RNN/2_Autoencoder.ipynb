{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JJ3OjSzIu08"
      },
      "source": [
        "<img src='http://www-scf.usc.edu/~ghasemig/images/sharif.png' alt=\"SUT logo\" width=200 height=200 align=left class=\"saturate\" >\n",
        "\n",
        "<br>\n",
        "<font face=\"Times New Roman\">\n",
        "<div dir=ltr align=center>\n",
        "<font color=0F5298 size=7>\n",
        "    Introduction to Machine Learning <br>\n",
        "<font color=2565AE size=5>\n",
        "    Computer Engineering Department <br>\n",
        "    Fall 2022<br>\n",
        "<font color=3C99D size=5>\n",
        "    Homework 3: Practical - Neural Network <br>\n",
        "<font color=696880 size=4>\n",
        "    Alireza Belal\n",
        "    \n",
        "    \n",
        "____\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQT5lLEJIu0-"
      },
      "source": [
        "### Full Name : Mahdi Shafiei\n",
        "### Student Number : 99109409\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxm8nwjJIu0-"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOjXgQPMIu0_"
      },
      "source": [
        "# 0. Preparation\n",
        "\n",
        "In this part, you will use a dataset related to COVID-19. Load your dataset using pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv9RsQrjIu0_",
        "outputId": "06414cdf-7c41-414e-ec1f-96aa9e510a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3803 1631\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "covid_data = pd.read_csv('/content/Covid Dataset.csv')\n",
        "categorical_feature_mask = covid_data.dtypes == object\n",
        "cateforical_cols = covid_data.columns[categorical_feature_mask].tolist()\n",
        "le = LabelEncoder()\n",
        "covid_data[cateforical_cols] = covid_data[cateforical_cols].apply(lambda col: le.fit_transform(col))\n",
        "covid_data = covid_data.astype(float)\n",
        "\n",
        "# Extract X and Y from the dataset\n",
        "X_total = covid_data.iloc[:, 0:20].values\n",
        "y_total = covid_data.iloc[:,20].values\n",
        "\n",
        "\n",
        "#SPLIT THE DATA INTO TRAIN AND TEST DATA \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_total, y_total, test_size = 0.3, random_state = 0)\n",
        "\n",
        "print(len(X_train), len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_6NKe2LIu1A"
      },
      "source": [
        "---------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M17FhTrtIu1A"
      },
      "source": [
        "# 1. DNN as nonlinear dimensionality reduction method (50 Points)\n",
        "\n",
        "Autoencoder is an unsupervised artificial neural network that compresses the data to lower dimension and then reconstructs the input back. Autoencoder finds the representation of the data in a lower dimension by focusing more on the important features getting rid of noise and redundancy. It's based on Encoder-Decoder architecture, where encoder encodes the high-dimensional data to lower-dimension and decoder takes the lower-dimensional data and tries to reconstruct the original high-dimensional data.\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1RTZwx4xL6zFV_nUENBgWlFKLKldPoyI-)\n",
        "\n",
        "In the above Diagram, X is the input data, z is the lower-dimension representation of input X and X’ is the reconstructed input data. The mapping of higher to lower dimensions can be linear or non-linear depending on the choice of the activation function.\n",
        "\n",
        "In this part you're gonna implement an autoencoder using Keras framework as dimensionally reduction module as explained [here](https://blog.keras.io/building-autoencoders-in-keras.html).\n",
        "(It would be ok to use PyTorch as well.)\n",
        "Reduce the dimension of the data to 2 dimensions and visualize the low-dimensional data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "moGEgpV999cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8573bf10-153e-4bb6-ffd0-a465ed3d3fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20,)\n"
          ]
        }
      ],
      "source": [
        "# import necessary libraries\n",
        "import keras\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "print(X_train[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DWtq4ClpIu1B"
      },
      "outputs": [],
      "source": [
        "# define layers (25 Points)\n",
        "\n",
        "input_data = keras.Input(X_train[0].shape)\n",
        "x = layers.Dense(15, activation='relu')(input_data)\n",
        "x = layers.Dense(7, activation='relu')(x)\n",
        "x = layers.Dense(5, activation='relu')(x)\n",
        "encoded = layers.Dense(2, activation='relu')(x)\n",
        "\n",
        "x = layers.Dense(5, activation='relu')(encoded)\n",
        "x = layers.Dense(7, activation='relu')(x)\n",
        "x = layers.Dense(15, activation='relu')(x)\n",
        "decoded = layers.Dense(20, activation='sigmoid')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_data, decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVqU5u62Iu1B",
        "outputId": "5c99bf4d-9509-4a1c-977f-cb91e4ba262a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/512\n",
            "77/77 [==============================] - 1s 5ms/step - loss: 0.1626 - val_loss: 0.1628\n",
            "Epoch 2/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1624 - val_loss: 0.1625\n",
            "Epoch 3/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1622 - val_loss: 0.1625\n",
            "Epoch 4/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1623 - val_loss: 0.1626\n",
            "Epoch 5/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1626 - val_loss: 0.1625\n",
            "Epoch 6/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1623 - val_loss: 0.1630\n",
            "Epoch 7/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1623 - val_loss: 0.1659\n",
            "Epoch 8/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1630 - val_loss: 0.1634\n",
            "Epoch 9/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1623 - val_loss: 0.1625\n",
            "Epoch 10/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1622 - val_loss: 0.1624\n",
            "Epoch 11/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1623 - val_loss: 0.1625\n",
            "Epoch 12/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1620 - val_loss: 0.1625\n",
            "Epoch 13/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1623 - val_loss: 0.1625\n",
            "Epoch 14/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1619 - val_loss: 0.1622\n",
            "Epoch 15/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1621 - val_loss: 0.1635\n",
            "Epoch 16/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1634 - val_loss: 0.1630\n",
            "Epoch 17/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1623 - val_loss: 0.1622\n",
            "Epoch 18/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1618 - val_loss: 0.1622\n",
            "Epoch 19/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1620 - val_loss: 0.1618\n",
            "Epoch 20/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1619 - val_loss: 0.1622\n",
            "Epoch 21/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1625 - val_loss: 0.1627\n",
            "Epoch 22/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1620 - val_loss: 0.1638\n",
            "Epoch 23/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1629 - val_loss: 0.1622\n",
            "Epoch 24/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1618 - val_loss: 0.1621\n",
            "Epoch 25/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1620 - val_loss: 0.1623\n",
            "Epoch 26/512\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.1618 - val_loss: 0.1621\n",
            "Epoch 27/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1620 - val_loss: 0.1632\n",
            "Epoch 28/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1619 - val_loss: 0.1619\n",
            "Epoch 29/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1618 - val_loss: 0.1629\n",
            "Epoch 30/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1630 - val_loss: 0.1673\n",
            "Epoch 31/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1666 - val_loss: 0.1629\n",
            "Epoch 32/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1621 - val_loss: 0.1621\n",
            "Epoch 33/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1618 - val_loss: 0.1625\n",
            "Epoch 34/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1619 - val_loss: 0.1619\n",
            "Epoch 35/512\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1620 - val_loss: 0.1620\n",
            "Epoch 36/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1622 - val_loss: 0.1619\n",
            "Epoch 37/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1619 - val_loss: 0.1621\n",
            "Epoch 38/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1621 - val_loss: 0.1631\n",
            "Epoch 39/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1621 - val_loss: 0.1620\n",
            "Epoch 40/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1619 - val_loss: 0.1632\n",
            "Epoch 41/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1624 - val_loss: 0.1623\n",
            "Epoch 42/512\n",
            "77/77 [==============================] - 1s 9ms/step - loss: 0.1618 - val_loss: 0.1621\n",
            "Epoch 43/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1616 - val_loss: 0.1616\n",
            "Epoch 44/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1617 - val_loss: 0.1621\n",
            "Epoch 45/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1618 - val_loss: 0.1624\n",
            "Epoch 46/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1615 - val_loss: 0.1619\n",
            "Epoch 47/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1620 - val_loss: 0.1620\n",
            "Epoch 48/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1620\n",
            "Epoch 49/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1620 - val_loss: 0.1620\n",
            "Epoch 50/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1619 - val_loss: 0.1621\n",
            "Epoch 51/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1616 - val_loss: 0.1619\n",
            "Epoch 52/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1614 - val_loss: 0.1621\n",
            "Epoch 53/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1616 - val_loss: 0.1626\n",
            "Epoch 54/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1619 - val_loss: 0.1620\n",
            "Epoch 55/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1617 - val_loss: 0.1623\n",
            "Epoch 56/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1615 - val_loss: 0.1617\n",
            "Epoch 57/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1614 - val_loss: 0.1621\n",
            "Epoch 58/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1614 - val_loss: 0.1618\n",
            "Epoch 59/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1618 - val_loss: 0.1617\n",
            "Epoch 60/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1614 - val_loss: 0.1624\n",
            "Epoch 61/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1616 - val_loss: 0.1631\n",
            "Epoch 62/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1622 - val_loss: 0.1630\n",
            "Epoch 63/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1618 - val_loss: 0.1621\n",
            "Epoch 64/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1619 - val_loss: 0.1624\n",
            "Epoch 65/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1616 - val_loss: 0.1616\n",
            "Epoch 66/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1616\n",
            "Epoch 67/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1618\n",
            "Epoch 68/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1613 - val_loss: 0.1615\n",
            "Epoch 69/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1657\n",
            "Epoch 70/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1626 - val_loss: 0.1617\n",
            "Epoch 71/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1617 - val_loss: 0.1620\n",
            "Epoch 72/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1621\n",
            "Epoch 73/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1615\n",
            "Epoch 74/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1622\n",
            "Epoch 75/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1617 - val_loss: 0.1619\n",
            "Epoch 76/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1613 - val_loss: 0.1616\n",
            "Epoch 77/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1611 - val_loss: 0.1618\n",
            "Epoch 78/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1627 - val_loss: 0.1628\n",
            "Epoch 79/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1624 - val_loss: 0.1626\n",
            "Epoch 80/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1618 - val_loss: 0.1619\n",
            "Epoch 81/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1617\n",
            "Epoch 82/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1613 - val_loss: 0.1621\n",
            "Epoch 83/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1618\n",
            "Epoch 84/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1611 - val_loss: 0.1617\n",
            "Epoch 85/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1613 - val_loss: 0.1617\n",
            "Epoch 86/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1617\n",
            "Epoch 87/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1617\n",
            "Epoch 88/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1617 - val_loss: 0.1631\n",
            "Epoch 89/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1618 - val_loss: 0.1621\n",
            "Epoch 90/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1619\n",
            "Epoch 91/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1616 - val_loss: 0.1614\n",
            "Epoch 92/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1613 - val_loss: 0.1628\n",
            "Epoch 93/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1618 - val_loss: 0.1629\n",
            "Epoch 94/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1623 - val_loss: 0.1621\n",
            "Epoch 95/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1616 - val_loss: 0.1622\n",
            "Epoch 96/512\n",
            "77/77 [==============================] - 1s 11ms/step - loss: 0.1615 - val_loss: 0.1625\n",
            "Epoch 97/512\n",
            "77/77 [==============================] - 1s 16ms/step - loss: 0.1614 - val_loss: 0.1617\n",
            "Epoch 98/512\n",
            "77/77 [==============================] - 1s 9ms/step - loss: 0.1614 - val_loss: 0.1630\n",
            "Epoch 99/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1618 - val_loss: 0.1616\n",
            "Epoch 100/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1613 - val_loss: 0.1630\n",
            "Epoch 101/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1613 - val_loss: 0.1615\n",
            "Epoch 102/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1614 - val_loss: 0.1616\n",
            "Epoch 103/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1611 - val_loss: 0.1614\n",
            "Epoch 104/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1612 - val_loss: 0.1614\n",
            "Epoch 105/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1610 - val_loss: 0.1613\n",
            "Epoch 106/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1613 - val_loss: 0.1616\n",
            "Epoch 107/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1613 - val_loss: 0.1618\n",
            "Epoch 108/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1611 - val_loss: 0.1617\n",
            "Epoch 109/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1626\n",
            "Epoch 110/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1618 - val_loss: 0.1618\n",
            "Epoch 111/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1616 - val_loss: 0.1618\n",
            "Epoch 112/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1623\n",
            "Epoch 113/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1618 - val_loss: 0.1615\n",
            "Epoch 114/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1613 - val_loss: 0.1616\n",
            "Epoch 115/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1610 - val_loss: 0.1616\n",
            "Epoch 116/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1615 - val_loss: 0.1619\n",
            "Epoch 117/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1613 - val_loss: 0.1613\n",
            "Epoch 118/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1612 - val_loss: 0.1618\n",
            "Epoch 119/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1610 - val_loss: 0.1614\n",
            "Epoch 120/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1609 - val_loss: 0.1616\n",
            "Epoch 121/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1611 - val_loss: 0.1618\n",
            "Epoch 122/512\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.1615 - val_loss: 0.1623\n",
            "Epoch 123/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1618 - val_loss: 0.1623\n",
            "Epoch 124/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1610 - val_loss: 0.1616\n",
            "Epoch 125/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1610 - val_loss: 0.1615\n",
            "Epoch 126/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1615 - val_loss: 0.1612\n",
            "Epoch 127/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1608 - val_loss: 0.1615\n",
            "Epoch 128/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1610 - val_loss: 0.1615\n",
            "Epoch 129/512\n",
            "77/77 [==============================] - 1s 9ms/step - loss: 0.1616 - val_loss: 0.1642\n",
            "Epoch 130/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1613 - val_loss: 0.1615\n",
            "Epoch 131/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1611 - val_loss: 0.1624\n",
            "Epoch 132/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1613 - val_loss: 0.1616\n",
            "Epoch 133/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1611 - val_loss: 0.1616\n",
            "Epoch 134/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1608 - val_loss: 0.1617\n",
            "Epoch 135/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1609 - val_loss: 0.1614\n",
            "Epoch 136/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1612 - val_loss: 0.1617\n",
            "Epoch 137/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1612\n",
            "Epoch 138/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1612 - val_loss: 0.1614\n",
            "Epoch 139/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1616\n",
            "Epoch 140/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1616 - val_loss: 0.1627\n",
            "Epoch 141/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1633 - val_loss: 0.1622\n",
            "Epoch 142/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1611 - val_loss: 0.1615\n",
            "Epoch 143/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1615\n",
            "Epoch 144/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1612 - val_loss: 0.1612\n",
            "Epoch 145/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1617\n",
            "Epoch 146/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1611 - val_loss: 0.1622\n",
            "Epoch 147/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1612 - val_loss: 0.1623\n",
            "Epoch 148/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1613 - val_loss: 0.1615\n",
            "Epoch 149/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1622\n",
            "Epoch 150/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1620 - val_loss: 0.1625\n",
            "Epoch 151/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1617 - val_loss: 0.1622\n",
            "Epoch 152/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1616 - val_loss: 0.1620\n",
            "Epoch 153/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1627 - val_loss: 0.1618\n",
            "Epoch 154/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1608 - val_loss: 0.1613\n",
            "Epoch 155/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1609 - val_loss: 0.1612\n",
            "Epoch 156/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1609 - val_loss: 0.1614\n",
            "Epoch 157/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1610 - val_loss: 0.1618\n",
            "Epoch 158/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1625 - val_loss: 0.1613\n",
            "Epoch 159/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1610 - val_loss: 0.1618\n",
            "Epoch 160/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1617\n",
            "Epoch 161/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1610 - val_loss: 0.1612\n",
            "Epoch 162/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1614\n",
            "Epoch 163/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1610 - val_loss: 0.1616\n",
            "Epoch 164/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1611 - val_loss: 0.1618\n",
            "Epoch 165/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1613\n",
            "Epoch 166/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.1612\n",
            "Epoch 167/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1606 - val_loss: 0.1618\n",
            "Epoch 168/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1607 - val_loss: 0.1619\n",
            "Epoch 169/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1613\n",
            "Epoch 170/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1612 - val_loss: 0.1645\n",
            "Epoch 171/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1613\n",
            "Epoch 172/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1610\n",
            "Epoch 173/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1606 - val_loss: 0.1610\n",
            "Epoch 174/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1605 - val_loss: 0.1610\n",
            "Epoch 175/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1615 - val_loss: 0.1617\n",
            "Epoch 176/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1611 - val_loss: 0.1611\n",
            "Epoch 177/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1607 - val_loss: 0.1611\n",
            "Epoch 178/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1609 - val_loss: 0.1617\n",
            "Epoch 179/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.1609\n",
            "Epoch 180/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1610 - val_loss: 0.1651\n",
            "Epoch 181/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1644 - val_loss: 0.1621\n",
            "Epoch 182/512\n",
            "77/77 [==============================] - 1s 11ms/step - loss: 0.1613 - val_loss: 0.1619\n",
            "Epoch 183/512\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.1608 - val_loss: 0.1613\n",
            "Epoch 184/512\n",
            "77/77 [==============================] - 1s 9ms/step - loss: 0.1606 - val_loss: 0.1619\n",
            "Epoch 185/512\n",
            "77/77 [==============================] - 1s 12ms/step - loss: 0.1641 - val_loss: 0.1625\n",
            "Epoch 186/512\n",
            "77/77 [==============================] - 1s 9ms/step - loss: 0.1618 - val_loss: 0.1618\n",
            "Epoch 187/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1612 - val_loss: 0.1615\n",
            "Epoch 188/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1612 - val_loss: 0.1617\n",
            "Epoch 189/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1608 - val_loss: 0.1619\n",
            "Epoch 190/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1626\n",
            "Epoch 191/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1613 - val_loss: 0.1615\n",
            "Epoch 192/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1608 - val_loss: 0.1613\n",
            "Epoch 193/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1611 - val_loss: 0.1612\n",
            "Epoch 194/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1607 - val_loss: 0.1615\n",
            "Epoch 195/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1610 - val_loss: 0.1615\n",
            "Epoch 196/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1611 - val_loss: 0.1615\n",
            "Epoch 197/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1607 - val_loss: 0.1612\n",
            "Epoch 198/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1611\n",
            "Epoch 199/512\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.1613 - val_loss: 0.1616\n",
            "Epoch 200/512\n",
            "77/77 [==============================] - 1s 9ms/step - loss: 0.1608 - val_loss: 0.1611\n",
            "Epoch 201/512\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.1606 - val_loss: 0.1616\n",
            "Epoch 202/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1608 - val_loss: 0.1622\n",
            "Epoch 203/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1609 - val_loss: 0.1615\n",
            "Epoch 204/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1606 - val_loss: 0.1619\n",
            "Epoch 205/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1608 - val_loss: 0.1620\n",
            "Epoch 206/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1609 - val_loss: 0.1612\n",
            "Epoch 207/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1612\n",
            "Epoch 208/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1607 - val_loss: 0.1619\n",
            "Epoch 209/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1611 - val_loss: 0.1613\n",
            "Epoch 210/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1607 - val_loss: 0.1614\n",
            "Epoch 211/512\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.1614 - val_loss: 0.1628\n",
            "Epoch 212/512\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.1611 - val_loss: 0.1612\n",
            "Epoch 213/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1605 - val_loss: 0.1613\n",
            "Epoch 214/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1609\n",
            "Epoch 215/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1610\n",
            "Epoch 216/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1611 - val_loss: 0.1620\n",
            "Epoch 217/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1614\n",
            "Epoch 218/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1630\n",
            "Epoch 219/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1612 - val_loss: 0.1614\n",
            "Epoch 220/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1614\n",
            "Epoch 221/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1614\n",
            "Epoch 222/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.1612\n",
            "Epoch 223/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1617\n",
            "Epoch 224/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1613 - val_loss: 0.1610\n",
            "Epoch 225/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1612\n",
            "Epoch 226/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1613 - val_loss: 0.1612\n",
            "Epoch 227/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1613\n",
            "Epoch 228/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1616\n",
            "Epoch 229/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1616\n",
            "Epoch 230/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1627\n",
            "Epoch 231/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1610\n",
            "Epoch 232/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.1616\n",
            "Epoch 233/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1610 - val_loss: 0.1616\n",
            "Epoch 234/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1610 - val_loss: 0.1638\n",
            "Epoch 235/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1615\n",
            "Epoch 236/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1614\n",
            "Epoch 237/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.1610\n",
            "Epoch 238/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1613\n",
            "Epoch 239/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1614\n",
            "Epoch 240/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1621 - val_loss: 0.1618\n",
            "Epoch 241/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1610 - val_loss: 0.1611\n",
            "Epoch 242/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1609\n",
            "Epoch 243/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1609\n",
            "Epoch 244/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1611 - val_loss: 0.1621\n",
            "Epoch 245/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1612 - val_loss: 0.1613\n",
            "Epoch 246/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1607 - val_loss: 0.1609\n",
            "Epoch 247/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1606 - val_loss: 0.1614\n",
            "Epoch 248/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1609 - val_loss: 0.1617\n",
            "Epoch 249/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1609 - val_loss: 0.1615\n",
            "Epoch 250/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1614\n",
            "Epoch 251/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1619\n",
            "Epoch 252/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1604 - val_loss: 0.1612\n",
            "Epoch 253/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1611\n",
            "Epoch 254/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1611 - val_loss: 0.1647\n",
            "Epoch 255/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1618 - val_loss: 0.1615\n",
            "Epoch 256/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1611\n",
            "Epoch 257/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1613\n",
            "Epoch 258/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1613\n",
            "Epoch 259/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.1609\n",
            "Epoch 260/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1614\n",
            "Epoch 261/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1639\n",
            "Epoch 262/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1617 - val_loss: 0.1620\n",
            "Epoch 263/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.1613\n",
            "Epoch 264/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1622\n",
            "Epoch 265/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1617\n",
            "Epoch 266/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.1607\n",
            "Epoch 267/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1613\n",
            "Epoch 268/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1617\n",
            "Epoch 269/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1612\n",
            "Epoch 270/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1615\n",
            "Epoch 271/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1609\n",
            "Epoch 272/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1621\n",
            "Epoch 273/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1610 - val_loss: 0.1616\n",
            "Epoch 274/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.1612\n",
            "Epoch 275/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1612\n",
            "Epoch 276/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1616\n",
            "Epoch 277/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1608\n",
            "Epoch 278/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1603 - val_loss: 0.1617\n",
            "Epoch 279/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.1614\n",
            "Epoch 280/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1609\n",
            "Epoch 281/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1616\n",
            "Epoch 282/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1607 - val_loss: 0.1614\n",
            "Epoch 283/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1609 - val_loss: 0.1612\n",
            "Epoch 284/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1604 - val_loss: 0.1609\n",
            "Epoch 285/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1606 - val_loss: 0.1613\n",
            "Epoch 286/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1605 - val_loss: 0.1608\n",
            "Epoch 287/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1617\n",
            "Epoch 288/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1614\n",
            "Epoch 289/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1612\n",
            "Epoch 290/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1626 - val_loss: 0.1617\n",
            "Epoch 291/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.1606\n",
            "Epoch 292/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1602 - val_loss: 0.1612\n",
            "Epoch 293/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1614\n",
            "Epoch 294/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1613\n",
            "Epoch 295/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1626\n",
            "Epoch 296/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1617 - val_loss: 0.1649\n",
            "Epoch 297/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1620 - val_loss: 0.1616\n",
            "Epoch 298/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1611\n",
            "Epoch 299/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1602 - val_loss: 0.1609\n",
            "Epoch 300/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1622\n",
            "Epoch 301/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1629\n",
            "Epoch 302/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1612 - val_loss: 0.1614\n",
            "Epoch 303/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1608\n",
            "Epoch 304/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.1607\n",
            "Epoch 305/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.1619\n",
            "Epoch 306/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1602 - val_loss: 0.1614\n",
            "Epoch 307/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1609\n",
            "Epoch 308/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.1610\n",
            "Epoch 309/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.1612\n",
            "Epoch 310/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.1608\n",
            "Epoch 311/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1609\n",
            "Epoch 312/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1607\n",
            "Epoch 313/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1605\n",
            "Epoch 314/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.1609\n",
            "Epoch 315/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1610\n",
            "Epoch 316/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1602 - val_loss: 0.1607\n",
            "Epoch 317/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.1611\n",
            "Epoch 318/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1602 - val_loss: 0.1606\n",
            "Epoch 319/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1604 - val_loss: 0.1607\n",
            "Epoch 320/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1600 - val_loss: 0.1604\n",
            "Epoch 321/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1600 - val_loss: 0.1607\n",
            "Epoch 322/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1605 - val_loss: 0.1611\n",
            "Epoch 323/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1602 - val_loss: 0.1608\n",
            "Epoch 324/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1610\n",
            "Epoch 325/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1602 - val_loss: 0.1613\n",
            "Epoch 326/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1611\n",
            "Epoch 327/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1602 - val_loss: 0.1609\n",
            "Epoch 328/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1606\n",
            "Epoch 329/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1609\n",
            "Epoch 330/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1609\n",
            "Epoch 331/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1600 - val_loss: 0.1628\n",
            "Epoch 332/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1617 - val_loss: 0.1619\n",
            "Epoch 333/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1609\n",
            "Epoch 334/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1602 - val_loss: 0.1609\n",
            "Epoch 335/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1611\n",
            "Epoch 336/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1610\n",
            "Epoch 337/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1606\n",
            "Epoch 338/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1606\n",
            "Epoch 339/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1610 - val_loss: 0.1621\n",
            "Epoch 340/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1609\n",
            "Epoch 341/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1608\n",
            "Epoch 342/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1600 - val_loss: 0.1608\n",
            "Epoch 343/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1600 - val_loss: 0.1608\n",
            "Epoch 344/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1599 - val_loss: 0.1603\n",
            "Epoch 345/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1619\n",
            "Epoch 346/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1629 - val_loss: 0.1620\n",
            "Epoch 347/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1616 - val_loss: 0.1612\n",
            "Epoch 348/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1602 - val_loss: 0.1605\n",
            "Epoch 349/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1602 - val_loss: 0.1605\n",
            "Epoch 350/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1597 - val_loss: 0.1609\n",
            "Epoch 351/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1602 - val_loss: 0.1608\n",
            "Epoch 352/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1607\n",
            "Epoch 353/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1601 - val_loss: 0.1604\n",
            "Epoch 354/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1600 - val_loss: 0.1612\n",
            "Epoch 355/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1600 - val_loss: 0.1610\n",
            "Epoch 356/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1608 - val_loss: 0.1605\n",
            "Epoch 357/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1599 - val_loss: 0.1602\n",
            "Epoch 358/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1598 - val_loss: 0.1606\n",
            "Epoch 359/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1598 - val_loss: 0.1619\n",
            "Epoch 360/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1601 - val_loss: 0.1612\n",
            "Epoch 361/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.1607\n",
            "Epoch 362/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1602 - val_loss: 0.1609\n",
            "Epoch 363/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1600 - val_loss: 0.1602\n",
            "Epoch 364/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1599 - val_loss: 0.1610\n",
            "Epoch 365/512\n",
            "77/77 [==============================] - 1s 11ms/step - loss: 0.1603 - val_loss: 0.1626\n",
            "Epoch 366/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1610 - val_loss: 0.1615\n",
            "Epoch 367/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1606\n",
            "Epoch 368/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1606\n",
            "Epoch 369/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1600 - val_loss: 0.1604\n",
            "Epoch 370/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1603\n",
            "Epoch 371/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1604\n",
            "Epoch 372/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1605\n",
            "Epoch 373/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1607\n",
            "Epoch 374/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1615\n",
            "Epoch 375/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1622\n",
            "Epoch 376/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.1605\n",
            "Epoch 377/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1600 - val_loss: 0.1605\n",
            "Epoch 378/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1604\n",
            "Epoch 379/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1606\n",
            "Epoch 380/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1605\n",
            "Epoch 381/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1599 - val_loss: 0.1610\n",
            "Epoch 382/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1600 - val_loss: 0.1601\n",
            "Epoch 383/512\n",
            "77/77 [==============================] - 1s 11ms/step - loss: 0.1597 - val_loss: 0.1613\n",
            "Epoch 384/512\n",
            "77/77 [==============================] - 1s 13ms/step - loss: 0.1609 - val_loss: 0.1609\n",
            "Epoch 385/512\n",
            "77/77 [==============================] - 1s 14ms/step - loss: 0.1600 - val_loss: 0.1610\n",
            "Epoch 386/512\n",
            "77/77 [==============================] - 1s 13ms/step - loss: 0.1601 - val_loss: 0.1602\n",
            "Epoch 387/512\n",
            "77/77 [==============================] - 1s 10ms/step - loss: 0.1596 - val_loss: 0.1603\n",
            "Epoch 388/512\n",
            "77/77 [==============================] - 1s 11ms/step - loss: 0.1599 - val_loss: 0.1605\n",
            "Epoch 389/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1602 - val_loss: 0.1624\n",
            "Epoch 390/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1601 - val_loss: 0.1613\n",
            "Epoch 391/512\n",
            "77/77 [==============================] - 1s 9ms/step - loss: 0.1606 - val_loss: 0.1607\n",
            "Epoch 392/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1600 - val_loss: 0.1605\n",
            "Epoch 393/512\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.1598 - val_loss: 0.1608\n",
            "Epoch 394/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1600 - val_loss: 0.1601\n",
            "Epoch 395/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1598 - val_loss: 0.1610\n",
            "Epoch 396/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1599 - val_loss: 0.1602\n",
            "Epoch 397/512\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.1597 - val_loss: 0.1607\n",
            "Epoch 398/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1597 - val_loss: 0.1602\n",
            "Epoch 399/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1602 - val_loss: 0.1606\n",
            "Epoch 400/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1597 - val_loss: 0.1603\n",
            "Epoch 401/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1602\n",
            "Epoch 402/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1600 - val_loss: 0.1616\n",
            "Epoch 403/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1612\n",
            "Epoch 404/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1609\n",
            "Epoch 405/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1610 - val_loss: 0.1606\n",
            "Epoch 406/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1602 - val_loss: 0.1609\n",
            "Epoch 407/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1604\n",
            "Epoch 408/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1595 - val_loss: 0.1602\n",
            "Epoch 409/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1597 - val_loss: 0.1599\n",
            "Epoch 410/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1609\n",
            "Epoch 411/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1607\n",
            "Epoch 412/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1598 - val_loss: 0.1608\n",
            "Epoch 413/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1598 - val_loss: 0.1609\n",
            "Epoch 414/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1605 - val_loss: 0.1605\n",
            "Epoch 415/512\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.1597 - val_loss: 0.1602\n",
            "Epoch 416/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1596 - val_loss: 0.1611\n",
            "Epoch 417/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1600\n",
            "Epoch 418/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1593 - val_loss: 0.1599\n",
            "Epoch 419/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1595 - val_loss: 0.1604\n",
            "Epoch 420/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1597 - val_loss: 0.1615\n",
            "Epoch 421/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1603\n",
            "Epoch 422/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1610\n",
            "Epoch 423/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1625\n",
            "Epoch 424/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1612\n",
            "Epoch 425/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1600 - val_loss: 0.1604\n",
            "Epoch 426/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1609\n",
            "Epoch 427/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1615\n",
            "Epoch 428/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1610\n",
            "Epoch 429/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1600 - val_loss: 0.1641\n",
            "Epoch 430/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1643 - val_loss: 0.1612\n",
            "Epoch 431/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1606\n",
            "Epoch 432/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1597 - val_loss: 0.1605\n",
            "Epoch 433/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1603\n",
            "Epoch 434/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1601\n",
            "Epoch 435/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1608\n",
            "Epoch 436/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1600\n",
            "Epoch 437/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1603\n",
            "Epoch 438/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1595 - val_loss: 0.1604\n",
            "Epoch 439/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1597 - val_loss: 0.1644\n",
            "Epoch 440/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1650 - val_loss: 0.1619\n",
            "Epoch 441/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.1615\n",
            "Epoch 442/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1605\n",
            "Epoch 443/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1605\n",
            "Epoch 444/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1626\n",
            "Epoch 445/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1613\n",
            "Epoch 446/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1606\n",
            "Epoch 447/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1603\n",
            "Epoch 448/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1595 - val_loss: 0.1601\n",
            "Epoch 449/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1598 - val_loss: 0.1599\n",
            "Epoch 450/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1595 - val_loss: 0.1608\n",
            "Epoch 451/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1606 - val_loss: 0.1603\n",
            "Epoch 452/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1600 - val_loss: 0.1604\n",
            "Epoch 453/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1603\n",
            "Epoch 454/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1613\n",
            "Epoch 455/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1595 - val_loss: 0.1601\n",
            "Epoch 456/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1592 - val_loss: 0.1599\n",
            "Epoch 457/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1594 - val_loss: 0.1601\n",
            "Epoch 458/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1594 - val_loss: 0.1602\n",
            "Epoch 459/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1601\n",
            "Epoch 460/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1594 - val_loss: 0.1644\n",
            "Epoch 461/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1602 - val_loss: 0.1604\n",
            "Epoch 462/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1594 - val_loss: 0.1607\n",
            "Epoch 463/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1601\n",
            "Epoch 464/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1607 - val_loss: 0.1603\n",
            "Epoch 465/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1597 - val_loss: 0.1621\n",
            "Epoch 466/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1610\n",
            "Epoch 467/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1604\n",
            "Epoch 468/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1624\n",
            "Epoch 469/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1600 - val_loss: 0.1603\n",
            "Epoch 470/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1630\n",
            "Epoch 471/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1607\n",
            "Epoch 472/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1599\n",
            "Epoch 473/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1592 - val_loss: 0.1599\n",
            "Epoch 474/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1593 - val_loss: 0.1605\n",
            "Epoch 475/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1594 - val_loss: 0.1599\n",
            "Epoch 476/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1602 - val_loss: 0.1605\n",
            "Epoch 477/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1595 - val_loss: 0.1600\n",
            "Epoch 478/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1602\n",
            "Epoch 479/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1593 - val_loss: 0.1605\n",
            "Epoch 480/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1599\n",
            "Epoch 481/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1603\n",
            "Epoch 482/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1595 - val_loss: 0.1595\n",
            "Epoch 483/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1595 - val_loss: 0.1605\n",
            "Epoch 484/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1601 - val_loss: 0.1605\n",
            "Epoch 485/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1602 - val_loss: 0.1620\n",
            "Epoch 486/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1598 - val_loss: 0.1603\n",
            "Epoch 487/512\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.1595 - val_loss: 0.1608\n",
            "Epoch 488/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1594 - val_loss: 0.1602\n",
            "Epoch 489/512\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1593 - val_loss: 0.1598\n",
            "Epoch 490/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1591 - val_loss: 0.1601\n",
            "Epoch 491/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1594 - val_loss: 0.1601\n",
            "Epoch 492/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1638\n",
            "Epoch 493/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 0.1603\n",
            "Epoch 494/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1597 - val_loss: 0.1611\n",
            "Epoch 495/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1616\n",
            "Epoch 496/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1607\n",
            "Epoch 497/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1597 - val_loss: 0.1600\n",
            "Epoch 498/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1597 - val_loss: 0.1603\n",
            "Epoch 499/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1592 - val_loss: 0.1602\n",
            "Epoch 500/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1593 - val_loss: 0.1608\n",
            "Epoch 501/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1613\n",
            "Epoch 502/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1611\n",
            "Epoch 503/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1594 - val_loss: 0.1600\n",
            "Epoch 504/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1600\n",
            "Epoch 505/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1595 - val_loss: 0.1604\n",
            "Epoch 506/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1594 - val_loss: 0.1600\n",
            "Epoch 507/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1593 - val_loss: 0.1602\n",
            "Epoch 508/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1597 - val_loss: 0.1601\n",
            "Epoch 509/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1593 - val_loss: 0.1601\n",
            "Epoch 510/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1593 - val_loss: 0.1607\n",
            "Epoch 511/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1610\n",
            "Epoch 512/512\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1594 - val_loss: 0.1601\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f48fe9fa490>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# train the model and reduce the dimension of the data (15 Points)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.fit(X_train, X_train, epochs=512, batch_size=50, validation_data=(X_test, X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "wZHaQ7USIu1C",
        "outputId": "78d2be0b-fddd-4703-fca4-cb6a609e2d61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119/119 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot the encoded data (10 Points)\n",
        "encoder = keras.Model(input_data, encoded)\n",
        "encoded_data = encoder.predict(X_train)\n",
        "\n",
        "colors = ['crimson' if y==1 else 'cyan' for y in y_train]\n",
        "plt.scatter(encoded_data[:, 0], encoded_data[:, 1], color=colors)\n",
        "plt.title('Train Data')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "encoded_data = encoder.predict(X_test)\n",
        "\n",
        "colors = ['crimson' if y==1 else 'cyan' for y in y_test]\n",
        "plt.scatter(encoded_data[:, 0], encoded_data[:, 1], color=colors)\n",
        "plt.title('Test Data')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see above, two classes have been seperated very well. Each data is pretty much classified by the axis that it lies on."
      ],
      "metadata": {
        "id": "yiW6PdPga1pa"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}